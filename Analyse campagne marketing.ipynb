{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8ec887",
   "metadata": {},
   "source": [
    "# Analyse de Campagne Marketing - Grande Distribution\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte et Objectifs\n",
    "\n",
    "**Client :** Direction Marketing d'une multinationale de la grande distribution\n",
    "\n",
    "### Objectifs Principaux\n",
    "1. **Analyser, visualiser et interpr√©ter** les donn√©es de campagne marketing\n",
    "2. **D√©finir les KPIs pertinents** pour √©valuer l'efficacit√© des campagnes\n",
    "3. **Pr√©dire la r√©ponse client** aux futures campagnes\n",
    "\n",
    "### Objectifs Finaux\n",
    "- Chiffrer l'efficacit√© des campagnes marketing\n",
    "- R√©aliser des KPIs et fournir des chiffres cl√©s\n",
    "- Cerner la cible client et comprendre le public cibl√©\n",
    "\n",
    "### Livrables\n",
    "- Analyses exploratoires compl√®tes\n",
    "- Mod√®les pr√©dictifs de r√©ponse client\n",
    "- Segmentation client (clustering)\n",
    "- Justification du feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c55b5",
   "metadata": {},
   "source": [
    "## Table des Mati√®res\n",
    "\n",
    "1. **Importation des Biblioth√®ques**\n",
    "2. **Chargement et D√©couverte des Donn√©es**\n",
    "3. **Nettoyage et Pr√©traitement des Donn√©es**\n",
    "4. **Feature Engineering**\n",
    "5. **D√©finition et Calcul des KPIs**\n",
    "6. **Segmentation Client (Clustering)**\n",
    "7. **Mod√©lisation Pr√©dictive**\n",
    "8. **Conclusions et Recommandations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9679aba",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Importation des Biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c692e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Toutes les biblioth√®ques ont √©t√© import√©es avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Machine Learning - Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Machine Learning - Mod√©lisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Machine Learning - √âvaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Ignorer les warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Toutes les biblioth√®ques ont √©t√© import√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333de1be",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è) Chargement et D√©couverte des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ebe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "df = pd.read_csv('Camp_Market.csv', sep=';')\n",
    "\n",
    "print(\"üìä Dimensions du dataset :\")\n",
    "print(f\"   Nombre de lignes : {df.shape[0]}\")\n",
    "print(f\"   Nombre de colonnes : {df.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Affichage des premi√®res lignes\n",
    "print(\"üìã Aper√ßu des donn√©es :\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f531e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations g√©n√©rales sur le dataset\n",
    "print(\"‚ÑπÔ∏è Informations sur le dataset :\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"Statistiques descriptives :\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcd399",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è) Nettoyage et Pr√©traitement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f211a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Dans Marital Status, remplacer \"Alone\" par \"Single\" et \"Absurd\" et \"YOLO\" par \"Other\"\n",
    "\n",
    "new_value = {\n",
    "    'Alone': 'Single',\n",
    "    'Absurd': 'Other',\n",
    "    'YOLO': 'Other'\n",
    "}\n",
    "df['Marital_Status'] = df['Marital_Status'].replace(new_value)\n",
    "print(\"Valeurs dans 'Marital_Status' remplac√©es avec succ√®s.\")\n",
    "print(df['Marital_Status'].head())  \n",
    "df.head()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 1.5 Dans la colonne Income, change les , en .\n",
    "df['Income'] = df['Income'].astype(str).str.replace(',', '.').astype(float)\n",
    "print(\"Virgules dans 'Income' remplac√©es par des points avec succ√®s.\")\n",
    "print(df['Income'].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#2 Supprimer la ligne avec income = 666666\n",
    "\n",
    "df = df[df['Income'] != 666666]\n",
    "print(\"Ligne avec 'Income' = 666666 supprim√©e avec succ√®s.\")\n",
    "# print(df['Income'].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "                                                \n",
    "\n",
    "\n",
    "\n",
    "#4 Supprimer les lignes si la somme des canaux de distrib (NumDealsPurchases + NumWebPurchases + NumCatalogPurchases + NumStorePurchases) = 0\n",
    "\n",
    "df['Total_Purchases'] = df['NumDealsPurchases'] + df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\n",
    "df = df[df['Total_Purchases'] != 0]\n",
    "df = df.drop(columns=['Total_Purchases'])\n",
    "print(\"Lignes avec somme des canaux de distribution √©gale √† 0 supprim√©es avec succ√®s.\")\n",
    "# print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "#5 Supprimer les lignes o√π la somme store/web/catalog < deals\n",
    "\n",
    "df['Sum_Other_Purchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\n",
    "df = df[df['Sum_Other_Purchases'] >= df['NumDealsPurchases']]\n",
    "df = df.drop(columns=['Sum_Other_Purchases'])\n",
    "print(\"Lignes o√π la somme store/web/catalog < deals supprim√©es avec succ√®s.\")\n",
    "# print(df.head())   \n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "#6 Trier visuelement les campagnes Marketing dans le bon ordre\n",
    "# ID - Year_birth - Education - Marital_Status - Income - Kidhome - Teenhome - Dt_Customer - Recency - MntWines - MntFruits - MntMeatProducts - MntFishProducts - MntSweetProducts - MntGoldProds - NumDealsPurchases - NumWebPurchases - NumCatalogPurchases - NumStorePurchases - NumWebVisitsMonth - AcceptedCmp1 - AcceptedCmp2 - AcceptedCmp3 - AcceptedCmp4 - AcceptedCmp5 - Response - Complain\n",
    "# Suppresion des colonnes Z_CostContact et Z_Revenue car elles ne sont pas utiles pour l'analyse\n",
    "\n",
    "desired_order = [\n",
    "    'ID', 'Year_Birth', 'Education', 'Marital_Status', 'Income', \n",
    "    'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', \n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n",
    "    'MntSweetProducts', 'MntGoldProds', \n",
    "    'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', \n",
    "    'NumStorePurchases', 'NumWebVisitsMonth', \n",
    "    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', \n",
    "    'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain'\n",
    "]\n",
    "df = df[desired_order]\n",
    "print(\"Colonnes tri√©es dans l'ordre souhait√© avec succ√®s.\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "#7 Afficher la somme du total des income\n",
    "\n",
    "total_income = df['Income'].sum()\n",
    "print(f\"La somme totale des revenus (Income) est : {total_income}\")\n",
    "\n",
    "# V√©rifier le nombre de valeurs manquantes avant\n",
    "print(f\"Nombre de valeurs manquantes dans Income avant : {df['Income'].isna().sum()}\")\n",
    "\n",
    "total_income = df['Income'].sum()\n",
    "print(f\"La somme totale des revenus (Income) est : {total_income}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674aa37",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è) Feature Engineering\n",
    "\n",
    "Cr√©ation de nouvelles variables pertinentes pour l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Ajout champ \"age\"\n",
    "\n",
    "actuel_year = 2014\n",
    "df['Age'] = actuel_year - df['Year_Birth']\n",
    "print(\"Champ 'Age' ajout√© avec succ√®s.\")\n",
    "print(df[['Year_Birth', 'Age']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#2 Ajout champ \"enfant totaux\"\n",
    "\n",
    "df['Total_Children'] = df['Kidhome'] + df['Teenhome']\n",
    "print(\"Champ 'Total_Children' ajout√© avec succ√®s.\")\n",
    "print(df[['Kidhome', 'Teenhome', 'Total_Children']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#3 Ajout champ \"achats totaux\"\n",
    "\n",
    "df['Total_Purchases'] = (df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + \n",
    "                          df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds'])\n",
    "print(\"Champ 'Total_Purchases' ajout√© avec succ√®s.\")\n",
    "print(df[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n",
    "          'MntSweetProducts', 'MntGoldProds', 'Total_Purchases']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#4 Ajout du caract√®re $ dans les champs Mnt\n",
    "\n",
    "money_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'Total_Purchases']\n",
    "for col in money_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  \n",
    "    df[col] = df[col].apply(lambda x: f\"${x:.2f}\" if pd.notnull(x) else \"\")\n",
    "print(\"Caract√®re '$' ajout√© aux champs Mnt avec succ√®s.\")\n",
    "print(df[money_columns].head())\n",
    "\n",
    "print(df[money_columns].head(10))\n",
    "print(df[money_columns].dtypes)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#5 Ajout champ somme store/web/catalog\n",
    "\n",
    "df['Total_Num_Purchases'] = df['NumStorePurchases'] + df['NumWebPurchases'] + df['NumCatalogPurchases']\n",
    "print(\"Champ 'Total_Num_Purchases' ajout√© avec succ√®s.\")\n",
    "print(df[['NumStorePurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'Total_Num_Purchases']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#5. ajout statuts conjugal simple (vie seul ou pas) couple ou single\n",
    "#6. total aux foyer\n",
    "# nombre de jours depuis l'inscription (se bas√© sur 30 juin 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a239d",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è) D√©finition et Calcul des KPIs\n",
    "\n",
    "### KPIs Cl√©s pour √âvaluer l'Efficacit√© des Campagnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a4a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CALCUL DES KPIs PRINCIPAUX ==========\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä CALCUL DES KPIs - INDICATEURS DE PERFORMANCE CL√âS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 1 : TAUX DE R√âPONSE PAR CAMPAGNE -----\n",
    "print(\"1Ô∏è‚É£ TAUX DE R√âPONSE PAR CAMPAGNE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "campagnes = ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']\n",
    "taux_reponse = {}\n",
    "\n",
    "for campagne in campagnes:\n",
    "    total_clients = len(df)\n",
    "    acceptations = df[campagne].sum()\n",
    "    taux = (acceptations / total_clients) * 100\n",
    "    taux_reponse[campagne] = taux\n",
    "    print(f\"   {campagne:20s} : {acceptations:4d} acceptations | Taux: {taux:6.2f}%\")\n",
    "\n",
    "print(f\"\\n   üìà Meilleure campagne : {max(taux_reponse, key=taux_reponse.get)} avec {max(taux_reponse.values()):.2f}%\")\n",
    "print(f\"   üìâ Moins bonne campagne : {min(taux_reponse, key=taux_reponse.get)} avec {min(taux_reponse.values()):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 2 : TAUX DE CONVERSION GLOBAL -----\n",
    "print(\"2Ô∏è‚É£ TAUX DE CONVERSION GLOBAL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df['Total_Acceptations'] = df[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']].sum(axis=1)\n",
    "clients_ayant_accepte = (df['Total_Acceptations'] > 0).sum()\n",
    "taux_conversion_global = (clients_ayant_accepte / len(df)) * 100\n",
    "\n",
    "print(f\"   Nombre total de clients : {len(df)}\")\n",
    "print(f\"   Clients ayant accept√© au moins une campagne : {clients_ayant_accepte}\")\n",
    "print(f\"   üìä TAUX DE CONVERSION GLOBAL : {taux_conversion_global:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 3 : REVENU MOYEN PAR CLIENT -----\n",
    "print(\"3Ô∏è‚É£ REVENU MOYEN PAR CLIENT (PANIER MOYEN)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calculer le total des achats par client si pas d√©j√† fait\n",
    "if 'Total_Purchases' not in df.columns:\n",
    "    df['Total_Purchases'] = (df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + \n",
    "                              df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds'])\n",
    "\n",
    "revenu_moyen = df['Total_Purchases'].mean()\n",
    "revenu_median = df['Total_Purchases'].median()\n",
    "revenu_total = df['Total_Purchases'].sum()\n",
    "\n",
    "print(f\"   Revenu total g√©n√©r√© : ${revenu_total:,.2f}\")\n",
    "print(f\"   üìä REVENU MOYEN par client : ${revenu_moyen:,.2f}\")\n",
    "print(f\"   üìä REVENU M√âDIAN par client : ${revenu_median:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 4 : ANALYSE PRODUITS PREMIUM (VIN & VIANDE) -----\n",
    "print(\"4Ô∏è‚É£ üç∑ü•© PERFORMANCE PRODUITS PREMIUM (VIN & VIANDE)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   üí° Insight : Corr√©lation forte avec TotalMnt (0.89 vin / 0.84 viande)\")\n",
    "print()\n",
    "\n",
    "part_vin = (df['MntWines'].sum() / df['Total_Purchases'].sum()) * 100\n",
    "part_viande = (df['MntMeatProducts'].sum() / df['Total_Purchases'].sum()) * 100\n",
    "part_premium = part_vin + part_viande\n",
    "\n",
    "print(f\"   üç∑ Part du VIN dans CA total : {part_vin:.1f}%\")\n",
    "print(f\"   ü•© Part de la VIANDE dans CA total : {part_viande:.1f}%\")\n",
    "print(f\"   ‚≠ê Part PRODUITS PREMIUM total : {part_premium:.1f}%\")\n",
    "\n",
    "# Identifier les clients \"Premium\" (gros acheteurs de vin/viande)\n",
    "df['Premium_Purchases'] = df['MntWines'] + df['MntMeatProducts']\n",
    "seuil_premium = df['Premium_Purchases'].quantile(0.75)\n",
    "clients_premium = (df['Premium_Purchases'] > seuil_premium).sum()\n",
    "pct_premium = (clients_premium / len(df)) * 100\n",
    "\n",
    "print(f\"\\n   üëë Clients PREMIUM (top 25% vin+viande) : {clients_premium} clients ({pct_premium:.1f}%)\")\n",
    "print(f\"   üí∞ Revenu moyen Premium : ${df[df['Premium_Purchases'] > seuil_premium]['Total_Purchases'].mean():,.2f}\")\n",
    "print(f\"   üí° STRAT√âGIE : Cibler ces clients avec offres exclusives vin/viande\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 5 : PERFORMANCE PAR CANAL (FOCUS CATALOGUE & MAGASIN) -----\n",
    "print(\"5Ô∏è‚É£ PERFORMANCE PAR CANAL DE DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   üí° Insight : Magasin = 82% volume | Catalogue = clients √† forte valeur (0.78)\")\n",
    "print()\n",
    "\n",
    "achats_web = df['NumWebPurchases'].sum()\n",
    "achats_catalog = df['NumCatalogPurchases'].sum()\n",
    "achats_store = df['NumStorePurchases'].sum()\n",
    "achats_deals = df['NumDealsPurchases'].sum()\n",
    "total_achats = achats_web + achats_catalog + achats_store + achats_deals\n",
    "\n",
    "print(f\"   üåê Web : {achats_web:5d} achats ({(achats_web/total_achats)*100:5.2f}%)\")\n",
    "print(f\"   üìñ Catalogue : {achats_catalog:5d} achats ({(achats_catalog/total_achats)*100:5.2f}%)\")\n",
    "print(f\"   üè™ Magasin : {achats_store:5d} achats ({(achats_store/total_achats)*100:5.2f}%)\")\n",
    "print(f\"   üí∞ Promotions : {achats_deals:5d} achats ({(achats_deals/total_achats)*100:5.2f}%)\")\n",
    "print(f\"   üìä TOTAL : {total_achats} achats\")\n",
    "\n",
    "# Analyse clients catalogue (haute valeur)\n",
    "clients_catalogue = df[df['NumCatalogPurchases'] > 0]\n",
    "print(f\"\\n   üìñ Clients achetant via CATALOGUE : {len(clients_catalogue)} ({len(clients_catalogue)/len(df)*100:.1f}%)\")\n",
    "print(f\"   üí∞ Revenu moyen Catalogue : ${clients_catalogue['Total_Purchases'].mean():,.2f}\")\n",
    "print(f\"   üí∞ Revenu moyen Autres : ${df[df['NumCatalogPurchases'] == 0]['Total_Purchases'].mean():,.2f}\")\n",
    "print(f\"   üìà Lift Catalogue : +{((clients_catalogue['Total_Purchases'].mean() / df[df['NumCatalogPurchases'] == 0]['Total_Purchases'].mean()) - 1) * 100:.1f}%\")\n",
    "print(f\"   üí° STRAT√âGIE : Clients catalogue = haute valeur, investir dans ce canal\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 6 : ROI PAR CAMPAGNE (Return On Investment) -----\n",
    "print(\"6Ô∏è‚É£ ROI - RETOUR SUR INVESTISSEMENT PAR CAMPAGNE\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   üí° Insight : Faible corr√©lation inter-campagnes = profils clients diff√©rents\")\n",
    "print()\n",
    "\n",
    "# Revenu moyen des clients ayant accept√© vs n'ayant pas accept√©\n",
    "for campagne in campagnes:\n",
    "    revenu_accepte = df[df[campagne] == 1]['Total_Purchases'].mean()\n",
    "    revenu_refuse = df[df[campagne] == 0]['Total_Purchases'].mean()\n",
    "    diff = revenu_accepte - revenu_refuse\n",
    "    lift = ((revenu_accepte / revenu_refuse) - 1) * 100 if revenu_refuse > 0 else 0\n",
    "    \n",
    "    print(f\"   {campagne:20s}:\")\n",
    "    print(f\"      Revenu moyen (accept√©) : ${revenu_accepte:,.2f}\")\n",
    "    print(f\"      Revenu moyen (refus√©)  : ${revenu_refuse:,.2f}\")\n",
    "    print(f\"      üìà Lift : +{lift:.1f}% | Diff√©rence : ${diff:,.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"   üí° STRAT√âGIE : Personnaliser chaque campagne selon le profil cible\")\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 7 : R√âCENCE ET ACTIVIT√â CLIENT -----\n",
    "print(\"7Ô∏è‚É£ R√âCENCE ET ACTIVIT√â CLIENT\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "recence_moyenne = df['Recency'].mean()\n",
    "visites_web_moyennes = df['NumWebVisitsMonth'].mean()\n",
    "\n",
    "print(f\"   üìÖ R√©cence moyenne : {recence_moyenne:.1f} jours depuis le dernier achat\")\n",
    "print(f\"   üåê Visites web moyennes : {visites_web_moyennes:.1f} visites/mois\")\n",
    "\n",
    "# Clients actifs (achat r√©cent < 30 jours)\n",
    "clients_actifs = (df['Recency'] <= 30).sum()\n",
    "taux_clients_actifs = (clients_actifs / len(df)) * 100\n",
    "print(f\"   ‚úÖ Clients actifs (<30j) : {clients_actifs} ({taux_clients_actifs:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- KPI 8 : SEGMENTATION PAR VALEUR CLIENT -----\n",
    "print(\"8Ô∏è‚É£ SEGMENTATION PAR VALEUR CLIENT\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Cr√©er des segments bas√©s sur les achats totaux\n",
    "df['Segment_Valeur'] = pd.cut(df['Total_Purchases'], \n",
    "                                bins=[0, 100, 500, 1000, float('inf')],\n",
    "                                labels=['Low Value', 'Medium Value', 'High Value', 'VIP'])\n",
    "\n",
    "segment_counts = df['Segment_Valeur'].value_counts()\n",
    "for segment in ['Low Value', 'Medium Value', 'High Value', 'VIP']:\n",
    "    if segment in segment_counts.index:\n",
    "        count = segment_counts[segment]\n",
    "        pct = (count / len(df)) * 100\n",
    "        avg_revenue = df[df['Segment_Valeur'] == segment]['Total_Purchases'].mean()\n",
    "        print(f\"   {segment:15s} : {count:4d} clients ({pct:5.2f}%) | Revenu moyen: ${avg_revenue:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ CALCUL DES KPIs TERMIN√â\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ----- R√âSUM√â STRAT√âGIQUE BAS√â SUR LES CORR√âLATIONS -----\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ R√âSUM√â STRAT√âGIQUE - INSIGHTS CORR√âLATIONS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"1Ô∏è‚É£  PRODUITS PREMIUM (Vin 0.89 / Viande 0.84)\")\n",
    "print(f\"    ‚Üí Repr√©sentent {part_premium:.1f}% du CA\")\n",
    "print(f\"    ‚Üí {clients_premium} clients Premium √† cibler avec offres exclusives\")\n",
    "print()\n",
    "print(\"2Ô∏è‚É£  CANAL CATALOGUE (Corr√©lation 0.78)\")\n",
    "print(f\"    ‚Üí Clients √† haute valeur (+{((clients_catalogue['Total_Purchases'].mean() / df[df['NumCatalogPurchases'] == 0]['Total_Purchases'].mean()) - 1) * 100:.0f}% vs autres)\")\n",
    "print(f\"    ‚Üí Investir davantage dans ce canal rentable\")\n",
    "print()\n",
    "print(\"3Ô∏è‚É£  CANAL MAGASIN (82% du volume)\")\n",
    "print(f\"    ‚Üí Canal principal, optimiser l'exp√©rience en magasin\")\n",
    "print()\n",
    "print(\"4Ô∏è‚É£  CAMPAGNES MARKETING (Corr√©lation inter-campagnes faible)\")\n",
    "print(f\"    ‚Üí Chaque campagne attire un profil diff√©rent\")\n",
    "print(f\"    ‚Üí N√©cessit√© de PERSONNALISER chaque campagne\")\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ea72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ANALYSE CROIS√âE : CAMPAGNES x CANAUX DE DISTRIBUTION ======\n",
    "print(\"=\"*80)\n",
    "print(\"üîé ANALYSE CROIS√âE : PERFORMANCE DES CAMPAGNES PAR CANAL DE DISTRIBUTION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Pour chaque campagne, calculer le nombre moyen d'achats par canal pour les clients ayant accept√© vs refus√©\n",
    "campagnes = ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']\n",
    "canaux = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumDealsPurchases']\n",
    "\n",
    "resultats = []\n",
    "for campagne in campagnes:\n",
    "    for canal in canaux:\n",
    "        mean_accepted = df[df[campagne] == 1][canal].mean()\n",
    "        mean_refused = df[df[campagne] == 0][canal].mean()\n",
    "        resultats.append({\n",
    "            'Campagne': campagne,\n",
    "            'Canal': canal,\n",
    "            'Moyenne_Accept√©': mean_accepted,\n",
    "            'Moyenne_Refus√©': mean_refused,\n",
    "            'Lift (%)': ((mean_accepted / mean_refused - 1) * 100) if mean_refused > 0 else None\n",
    "        })\n",
    "\n",
    "df_croise = pd.DataFrame(resultats)\n",
    "\n",
    "print(\"Tableau comparatif : Achats moyens par canal selon acceptation/refus de chaque campagne\\n\")\n",
    "display(df_croise.pivot(index='Campagne', columns='Canal', values=['Moyenne_Accept√©', 'Moyenne_Refus√©', 'Lift (%)']).round(2))\n",
    "\n",
    "print(\"\\nInterpr√©tation :\")\n",
    "print(\"- Ce tableau permet d'identifier pour chaque campagne quels canaux sont les plus efficaces pour convertir les clients.\")\n",
    "print(\"- Un lift positif indique que les clients ayant accept√© la campagne ach√®tent plus via ce canal que ceux qui l'ont refus√©e.\")\n",
    "print(\"- Cela aide √† adapter la strat√©gie de distribution pour chaque campagne.\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151a66d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è) R√©duction de la dimensionnalit√© (PCA) et Clustering\n",
    "\n",
    "### 5.1 Pr√©paration des donn√©es et projection PCA (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Pr√©paration des donn√©es et PCA (3D)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# S'assurer que le DataFrame df est charg√© (fallback au CSV brut si besoin)\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_csv('Campagne_Market.csv', sep=';')\n",
    "    print(\"‚ö†Ô∏è df n'√©tait pas en m√©moire; chargement direct depuis le CSV.\")\n",
    "\n",
    "# 1) S√©lection des colonnes num√©riques uniquement\n",
    "X_num = df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# 2) Retirer les identifiants et variables √† forte fuite potentielle (optionnel)\n",
    "drop_cols = [col for col in ['ID'] if col in X_num.columns]\n",
    "X_num = X_num.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 3) Imputation simple (m√©diane) pour valeurs manquantes\n",
    "for c in X_num.columns:\n",
    "    if X_num[c].isna().any():\n",
    "        X_num[c] = X_num[c].fillna(X_num[c].median())\n",
    "\n",
    "# 4) Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "# 5) PCA en 3 composantes\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PC1','PC2','PC3'])\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "print(\"Variance expliqu√©e par composante (PC1, PC2, PC3) :\", np.round(explained, 4))\n",
    "print(f\"Variance expliqu√©e cumul√©e (3D) : {explained.cumsum()[-1]:.3f}\")\n",
    "\n",
    "# 6) Visualisation 3D de la projection PCA\n",
    "# Couleur informative si dispo: pr√©f√©rer Total_Purchases, sinon Income, sinon aucune couleur\n",
    "color_col = None\n",
    "for cand in ['Total_Purchases','Income']:\n",
    "    if cand in df.columns:\n",
    "        color_col = cand\n",
    "        break\n",
    "\n",
    "if color_col is not None:\n",
    "    fig = px.scatter_3d(df_pca, x='PC1', y='PC2', z='PC3',\n",
    "                        color=df[color_col],\n",
    "                        color_continuous_scale='Viridis',\n",
    "                        title='Projection PCA (3D)')\n",
    "else:\n",
    "    fig = px.scatter_3d(df_pca, x='PC1', y='PC2', z='PC3', title='Projection PCA (3D)')\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6fa30",
   "metadata": {},
   "source": [
    "### 5.2 D√©termination du nombre optimal de clusters et choix de m√©thode (Silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Choix du nombre de clusters et de la m√©thode (Silhouette)\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# V√©rifier que X_pca existe (sinon relancer 5.1)\n",
    "if 'X_pca' not in globals():\n",
    "    raise RuntimeError(\"X_pca introuvable. Ex√©cutez d'abord la cellule 5.1 (PCA).\")\n",
    "\n",
    "n_samples = X_pca.shape[0]\n",
    "k_max_possible = max(2, min(10, n_samples - 1))\n",
    "k_values = list(range(2, k_max_possible + 1))\n",
    "\n",
    "results = []\n",
    "for k in k_values:\n",
    "    # KMeans\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_km = km.fit_predict(X_pca)\n",
    "    sil_km = silhouette_score(X_pca, labels_km)\n",
    "    results.append({'method':'KMeans','k':k,'silhouette':sil_km})\n",
    "    \n",
    "    # Agglomerative (Ward)\n",
    "    ag = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels_ag = ag.fit_predict(X_pca)\n",
    "    sil_ag = silhouette_score(X_pca, labels_ag)\n",
    "    results.append({'method':'Agglomerative','k':k,'silhouette':sil_ag})\n",
    "\n",
    "df_scores = pd.DataFrame(results)\n",
    "best_row = df_scores.loc[df_scores['silhouette'].idxmax()]\n",
    "best_method = best_row['method']\n",
    "best_k = int(best_row['k'])\n",
    "best_score = best_row['silhouette']\n",
    "\n",
    "print(\"Scores de silhouette par m√©thode et k :\\n\", df_scores.pivot(index='k', columns='method', values='silhouette').round(3))\n",
    "print()\n",
    "print(f\"‚úÖ Meilleur choix: {best_method} avec k={best_k} (silhouette={best_score:.3f})\")\n",
    "\n",
    "# Visualisation des scores\n",
    "plt.figure(figsize=(7,4))\n",
    "for method in ['KMeans','Agglomerative']:\n",
    "    subset = df_scores[df_scores['method']==method]\n",
    "    plt.plot(subset['k'], subset['silhouette'], marker='o', label=method)\n",
    "plt.title('Silhouette vs k (PCA 3D)')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Conserver le meilleur choix en variables globales\n",
    "best_model_name = best_method\n",
    "best_n_clusters = best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb7b24",
   "metadata": {},
   "source": [
    "### 5.3 Application du clustering sur l'espace PCA et visualisation 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23476a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Application du clustering choisi et 3D-plot\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# S√©curiser les pr√©requis\n",
    "if 'X_pca' not in globals():\n",
    "    raise RuntimeError(\"X_pca introuvable. Ex√©cutez d'abord la cellule 5.1 (PCA).\")\n",
    "if 'best_model_name' not in globals() or 'best_n_clusters' not in globals():\n",
    "    raise RuntimeError(\"Meilleur mod√®le non d√©fini. Ex√©cutez d'abord la cellule 5.2.\")\n",
    "\n",
    "# Fit final du meilleur mod√®le\n",
    "if best_model_name == 'KMeans':\n",
    "    model = KMeans(n_clusters=best_n_clusters, random_state=42, n_init=10)\n",
    "elif best_model_name == 'Agglomerative':\n",
    "    model = AgglomerativeClustering(n_clusters=best_n_clusters, linkage='ward')\n",
    "else:\n",
    "    raise ValueError(f\"M√©thode non reconnue: {best_model_name}\")\n",
    "\n",
    "labels = model.fit_predict(X_pca)\n",
    "sil = silhouette_score(X_pca, labels)\n",
    "\n",
    "# Ajouter les labels au df et √† df_pca\n",
    "df['Cluster'] = labels\n",
    "df_pca['Cluster'] = labels\n",
    "\n",
    "print(f\"Clusters obtenus: {np.bincount(labels)} (k={best_n_clusters})\")\n",
    "print(f\"Score de silhouette final: {sil:.3f}\")\n",
    "\n",
    "# Visualisation 3D des clusters sur l'espace PCA\n",
    "fig = px.scatter_3d(df_pca, x='PC1', y='PC2', z='PC3',\n",
    "                    color=df_pca['Cluster'].astype(str),\n",
    "                    title=f'Clustering {best_model_name} sur PCA (k={best_n_clusters})',\n",
    "                    labels={'color':'Cluster'})\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.85))\n",
    "fig.show()\n",
    "\n",
    "# Optionnel: centroids en 3D (pour KMeans)\n",
    "try:\n",
    "    centers = model.cluster_centers_  # disponible pour KMeans\n",
    "    centers_df = pd.DataFrame(centers, columns=['PC1','PC2','PC3'])\n",
    "    import plotly.graph_objects as go\n",
    "    fig_centers = px.scatter_3d(df_pca, x='PC1', y='PC2', z='PC3', color=df_pca['Cluster'].astype(str),\n",
    "                                title=f'Clusters + Centroides (KMeans, k={best_n_clusters})')\n",
    "    fig_centers.add_trace(go.Scatter3d(x=centers_df['PC1'], y=centers_df['PC2'], z=centers_df['PC3'],\n",
    "                                       mode='markers', marker=dict(size=8, color='black', symbol='x'),\n",
    "                                       name='Centroids'))\n",
    "    fig_centers.show()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23e364",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è) Mod√©lisation Pr√©dictive\n",
    "\n",
    "### 8.1 Pr√©paration des donn√©es pour la pr√©diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bcef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9adebde3",
   "metadata": {},
   "source": [
    "### 8.2 Entra√Ænement de plusieurs mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1dd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce613e25",
   "metadata": {},
   "source": [
    "### 8.3 Comparaison des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28a638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "990ae85f",
   "metadata": {},
   "source": [
    "### 8.4 Analyse d√©taill√©e du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5397df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f2e79e",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è) Conclusions et Recommandations\n",
    "\n",
    "### 9.1 Synth√®se des R√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd19647",
   "metadata": {},
   "source": [
    "### 9.2 Recommandations Strat√©giques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abb92f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion Finale\n",
    "\n",
    "Cette analyse compl√®te a permis de :\n",
    "\n",
    "\n",
    "### Points Forts de l'Analyse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
